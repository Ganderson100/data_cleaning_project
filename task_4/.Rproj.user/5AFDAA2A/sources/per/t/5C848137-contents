---
title: "Task 4 - Halloween Candy Data"
author: "Greg Anderson, DE2 Data Analysis"
date: "14/11/2019"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: task4_styles.css
  pdf_document: default
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# load in cleaned data
library(here)
here::here()
clean_candy <- read_csv(here("clean_data/clean_candy.csv"))
```

# Introduction

This report includes:  

* A brief introduction to the haloween candy dataset  
* A list of assumptions made  
* The steps taken to clean the data  
* The answers to the questions presented in the task brief  
* Other interesting analyses or conclusions  

![](images/candycorn.png) 

## The dataset

The halloween candy data is taken from a survey primarily used to produce hierarchy data of the most popular candy.  

The raw data was held in three .xlsx files covering survey responses from 2015, 2016 and 2017.  

The raw data and analysis can be accessed on the [Science Creative Quarterly](https://www.scq.ubc.ca/so-much-candy-data-seriously/) website.


## Assumptions

Project assumptions:  

1. The focus of the analysis was candy related questions from the survey.  
2. Analysis of other survey questions was not required.  
3. The data extracted and cleaned for analysis were:  

    * age  
    * candy  
    * whether the respondent was trick or treating or not  
    * gender  
    * candy rating  
    * country  
    * year  


## Cleaning the data

A number of steps were taken to address significant data quality issues.

The steps included:  

1. An initial cleaning of the column names using the package _'Janitor'_ and the function 'clean_names()' to remove special characters and spaces and to convert to lower case.    
2. Converting the data from wide to long format using the 'pivot_longer()' function from the 'Tidyr' package. Specific column numbers were selected in each data set that contained candy names to be included in the pivot.   
3. Dropped unwanted columns from the survey responses that were not required for analysis.  
4. Renaming column names to age, candy_name, rating, trick_or_treating, country, gender,  & year.  
5. Added "gender" and "country" columns to the 2015 data with NAs 
6. Added a "year" column to all three files in case further time series analysis was required.  
7. Orderded the columns across the three files in preparation for binding.  
8. Bound the rows across three files using 'rbind()'.    
9. The 'age' column was changed from character type to integer to remove responses provided as a text string rather than a number e.g. "old". NAs replaced such instances.  
10. For the 'candy_name' column in 2017 the following text was removed using str_replace() -  "q6_" 
11. Hard coding changes to the "country" column to address the considerable variation in the way some countries were provided in survey responses.  Also changed a significant number of responses to NA where responses were provided that were not recognised countries.  
12. Identified outliers in the age column e.g 1800.  Decided to replace any ages over 120 with NA.  


# Analysis

## Question 1
**What is the total number of candy ratings given across the three years. (number of candy ratings, not number of raters. Donâ€™t count missing values)**

```{r}
# ordedred table of number of ratings 
total_candy_ratings <- clean_candy %>%
  select(candy_name, rating) %>%
  drop_na() %>%
  summarise(number_of_ratings = n()) 

total_candy_ratings

```

## Question 2
**What was the average age of people who are going out trick or treating and the average age of people not going trick or treating?**

```{r}
# average age trick or treating
average_age_trick_or_treating <- clean_candy %>%
  select(age, trick_or_treating) %>%
  drop_na() %>%
  filter(trick_or_treating == "Yes") %>%
  summarise(trick_or_treating_average_age = mean(age))

average_age_trick_or_treating

# average age not trick or treating
average_age_not_trick_or_treating <- clean_candy %>%
  select(age, trick_or_treating) %>%
  drop_na() %>%
  filter(trick_or_treating == "No") %>%
  summarise(not_trick_or_treating_average_age = mean(age))
  
average_age_not_trick_or_treating
```

## Question 3
**For each of joy, despair and meh, which candy bar received the most of these ratings?**

```{r}
joy_ratings <- clean_candy %>%
  select(candy_name, rating) %>%
  drop_na() %>%
  filter(rating == "JOY") %>%
  group_by(candy_name) %>%
  summarise(number_of_joy_ratings = max(length(rating))) %>%
  top_n(1)

meh_ratings <- clean_candy %>%
  select(candy_name, rating) %>%
  drop_na() %>%
  filter(rating == "MEH") %>%
  group_by(candy_name) %>%
  summarise(number_of_meh_ratings = max(length(rating))) %>%
  top_n(1)

despair_ratings <- clean_candy %>%
  select(candy_name, rating) %>%
  drop_na() %>%
  filter(rating == "DESPAIR") %>%
  group_by(candy_name) %>%
  summarise(number_of_despair_ratings = max(length(rating))) %>%
  top_n(1)

joy_ratings
meh_ratings
despair_ratings

```

## Question 4
**How many people rated Starburst as despair?**

```{r}
starburst_despair <- clean_candy %>%
  select(candy_name, rating) %>%
  filter(candy_name == "starburst") %>%
  filter(rating == "DESPAIR") %>%
  summarise(number_starburst_rated_despair = n())

starburst_despair
```

# Conclusions
Recommend improving data collection practices to at least prevent respondents from entering free text.